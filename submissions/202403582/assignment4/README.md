# Assignment 4: Data Collection & Analysis  
한국외대 AI융합대학 — 202403582 Seungho Lee

본 문서는 Assignment 4 제출물의 README입니다.  
이 프로젝트는 한국어 대학 강의 데이터(AI Hub)를 기반으로, 이후 Assignment 5에서 사용할 “강의자료 자동 요약 및 핵심 포인트 추출기” 모델을 위한 데이터 탐색적 분석(EDA)을 수행합니다.

---

## 1. 데이터 개요

### 데이터 출처
- AI Hub: 한국어 대학 강의 데이터
- 링크: https://www.aihub.or.kr/aihubdata/data/view.do?dataSetSn=71627

### 데이터 설명
본 과제에서는 AI Hub에서 제공하는 데이터 전체가 아닌, 다음 조건에 맞추어 TL(라벨링 데이터) -> **컴퓨터통신(eng/comp)** 강의만 선별하여 사용하였다.

- 분할 파일 TL.zip.part0 / part1 → 병합하여 TL.zip(전체 Training용 라벨링 데이터) 구성
- TL.zip 내부에서 **eng/comp/** 폴더만 선택적 추출
- 모든 JSON 파일에서 `06_transcription → 1_text` 필드(문장 단위 텍스트)를 추출
- (lecture_id, major, sentence) 형태로 정제하여 최종 CSV 생성

### 최종 데이터 파일
- 파일명: `comp_sentences.csv`
- 크기: 약 **15MB**
- 문장 수: **122,144 문장**
- 강의 수: **367개**
- 컬럼 구성:
  - lecture_id  
  - major  
  - sentence  

---

## 2. 분석 환경

- Python 3 (Google Colab)
- Pandas, Matplotlib, re, collections

Notebook 파일:  
`data-analysis.ipynb`

---

## 3. 수행한 EDA 내용 요약

### (1) 데이터 로드 및 기본 정보 확인
- 전체 크기: (122,144, 3)
- 모든 컬럼은 object 타입
- 강의마다 서로 다른 문장 수를 가짐

**의미**  
데이터 구조와 양을 확인함으로써 향후 모델 입력 길이, 샘플링 전략, batch 크기 등을 설계할 수 있음.

---

### (2) 결측치 및 중복 데이터 검사
- 결측치: **0건**
- 중복 문장: **2,909건**

**발견**  
중복 문장이 존재하며, 이는 특정 문장이 모델 학습에서 과도하게 영향을 줄 수 있음을 의미한다.  
Assignment 5에서 모델 학습 시 중복 제거 또는 down-sampling 필요성이 있음.

---

### (3) 문장 길이 분석
- 평균: 약 46.9자
- 최대: 567자
- 최소: 1자
- IQR 기준으로도 길이 편차가 매우 큼

**의미**  
문장 길이 분포를 기반으로 모델 max_length 설정 가능  
(예: 128 token 또는 256 token 등)

**시각화 포함**  
- 문장 길이 히스토그램

이로 인해 긴 문장의 비율을 직관적으로 확인할 수 있었음.

---

### (4) 강의 단위 분포 분석
- lecture_id 개수: 367개
- Top 20 강의는 각각 800~1400문장 수준
- 반면 일부 강의는 100문장 이하

**발견**  
강의 간 극심한 데이터 불균형이 존재.  
이는 모델 학습 시 특정 강의 스타일이 과도하게 반영되는 오버피팅 위험이 있음.

**시각화 포함**  
- 강의별 문장 수 Top 20 bar chart

---

### (5) 자주 등장하는 단어 분석
Tokenizer를 이용해 한글/영문/숫자를 단위로 토큰화 후 빈도 분석 수행.

Top 20 단어:
- "이", "그래서", "이제", "어", "자", …

**발견 및 의미**
- filler word가 매우 많음 → stopword 처리 필요
- 전문 용어("필터", "주파수", "신호" 등)는 빈도 상위에 등장하지 않아  
  강의 특성상 구어체 표현이 많음을 확인할 수 있음
- 전처리 과정에서 의미 없는 구어체 제거 또는 가중치 조정 필요

---

## 4. 데이터 품질 문제 정리

### (1) 중복 문장 존재  
→ 모델 편향 발생 가능  
→ 해결: deduplication 적용 필요

### (2) 강의 간 문장 수 불균형  
→ 데이터 samplng 필요  
(ex. 상위 10강의는 일정 비율 샘플링, 하위 강의는 전체 유지)

### (3) filler word 과다  
→ stopword list 커스터마이징 필요

### (4) 극단적 길이의 문장 존재  
→ 너무 긴 문장은 모델 max_length 초과 가능  
→ 적절한 cutoff 전략 필요 (예: 95 percentile 기준)

---

## 5. 향후 모델링에 미칠 영향

Assignment 5(모델 학습)에서 다음과 같은 의사결정에 직접적으로 활용된다.

1. **토큰 길이 설정**
   - 평균/중앙값 기준으로 max_length를 합리적으로 설정 가능

2. **데이터 샘플링 필요성**
   - 강의별 문장 수가 크게 다르므로 균형 유지 필요

3. **전처리 규칙 설계**
   - 구어체 filler word 정제
   - 중복 문장 제거
   - 긴 문장 truncate 또는 분할 전략 수립

4. **모델 평가 전략**
   - 강의 단위로 train/val split 고려 가능

---


---

## 6. 결론

본 연구에서 수행한 탐색적 분석은  
향후 “강의자료 자동 요약 및 핵심 포인트 추출기” 모델의 데이터 전처리와 학습 설계 전반에 중요한 기초 자료로 사용될 것이다.

특히:
- 문장 길이 문제
- 강의 간 데이터 불균형
- 과도한 filler word
- 중복 문장
등의 이슈를 명확히 확인함으로써 Assignment 5에서 더 안정적이고 일반화 성능이 높은 모델을 구축할 수 있다.
